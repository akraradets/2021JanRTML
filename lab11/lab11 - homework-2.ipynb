{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class NaiveCustomLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        \n",
    "        # Parameters for computing i_t\n",
    "        self.U_i = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_i = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        # Parameters for computing f_t\n",
    "        self.U_f = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_f = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        # Parameters for computing c_t\n",
    "        self.U_c = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_c = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        # Parameters for computing o_t\n",
    "        self.U_o = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_o = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "                \n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "         \n",
    "    def forward(self, x, init_states=None):\n",
    "        \"\"\"\n",
    "        forward: Run input x through the cell. Assumes x.shape is (batch_size, sequence_length, input_size)\n",
    "        \"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        if init_states is None:\n",
    "            h_t, c_t = (\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "            \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            i_t = torch.sigmoid(x_t @ self.U_i + h_t @ self.V_i + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.U_f + h_t @ self.V_f + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.U_c + h_t @ self.V_c + self.b_c)\n",
    "            o_t = torch.sigmoid(x_t @ self.U_o + h_t @ self.V_o + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            \n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "        \n",
    "        # Reshape hidden_seq tensor to (batch size, sequence length, hidden_size)\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserved word tokens\n",
    "\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "\n",
    "    def __init__(self):        \n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a Voc object\n",
    "\n",
    "def readVocs(datafile):\n",
    "    print(\"Reading lines...\")    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc()\n",
    "    return voc, pairs\n",
    "\n",
    "# Boolean function returning True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using the filterPair predicate\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "\n",
    "def loadPrepareData(datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 10552 sentence pairs\n",
      "Trimmed to 8370 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 3467\n",
      "\n",
      "pairs:\n",
      "['now im left with this gay name', 'p']\n",
      "['p', 'part']\n",
      "['part', 'hey everyone']\n",
      "['hey everyone', 'ah well']\n",
      "['ah well', 'nick u']\n",
      "['nick u', 'u is a gay name .']\n",
      "['u is a gay name .', '. action gives u a golf clap .']\n",
      "['. action gives u a golf clap .', '']\n",
      "['', 'join']\n",
      "['join', 'hi u']\n"
     ]
    }
   ],
   "source": [
    "# !wget https://github.com/dsai-asia/RTML/raw/main/Labs/11-LSTMs/chatDataset.txt\n",
    "\n",
    "# Load/Assemble Voc and pairs\n",
    "\n",
    "datafile = 'nps.txt'\n",
    "voc, pairs = loadPrepareData(datafile)\n",
    "\n",
    "# Print some pairs to validate\n",
    "\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keep_words 1388 / 3464 = 0.4007\nTrimmed from 8370 pairs to 5600, 0.6691 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "# Trim vocabulary and pairs\n",
    "\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(lpairs)\n",
    "testpairs = pairs[3920:]\n",
    "pairs  = pairs[:3920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Return a padded input sequence tensor and the lengths of each original sequence\n",
    "\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Return a padded target sequence tensor, a padding mask, and the max target length\n",
    "\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Return all items for a given batch of pairs\n",
    "\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "# Example for validation\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['now im left with this gay name', 'p'], ['p', 'part'], ['part', 'hey everyone'], ['hey everyone', 'ah well'], ['ah well', 'nick u']]\n[['now im left with this gay name', 'p'], ['hey everyone', 'ah well'], ['ah well', 'nick u'], ['p', 'part'], ['part', 'hey everyone']]\ntensor([[  20,   65,   11, 1277,   17],\n        [  20,  222,    2,   20,    2],\n        [ 979,   83,    0,  927,    0],\n        [  20,  348,    0,    2,    0],\n        [   2,  453,    0,    0,    0],\n        [   0,    2,    0,    0,    0]])\ntensor([[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 0, 1, 0],\n        [1, 1, 0, 1, 0],\n        [1, 1, 0, 0, 0],\n        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n6\n"
     ]
    }
   ],
   "source": [
    "pair_batch = pairs[:5]\n",
    "print(pair_batch)\n",
    "pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "print(pair_batch)\n",
    "print(target_variable)\n",
    "print(mask)\n",
    "print(max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        \n",
    "        embedded = self.embedding(input_seq)\n",
    "\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths.cpu())\n",
    "        \n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        \n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        \n",
    "        return outputs, hidden\n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        \n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "       \n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))#, bidirectional=True)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "  \n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    \n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    \n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    \n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    \n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            \n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            \n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    losslist = []\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        \n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        \n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        \n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "            losslist.append(print_loss_avg)\n",
    "        \n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            print(directory)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n",
    "    return losslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        \n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        \n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "       \n",
    "        for _ in range(max_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            \n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        \n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "  \n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    \n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    \n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    \n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    \n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    \n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            \n",
    "            input_sentence = input('> ')\n",
    "            \n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            \n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            \n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            \n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "\n",
    "hidden_size = 512\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 4\n",
    "dropout = 0.5\n",
    "batch_size = 256 \n",
    "loadFilename = None\n",
    "\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:48: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:38: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "Iteration: 6000; Percent complete: 100.0%; Average loss: 0.6777\n",
      "content_nps/cb_model/Chat/2-4_512\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'content_nps/'\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 6000\n",
    "print_every = 10\n",
    "save_every = 2000\n",
    "loadFilename = None\n",
    "corpus_name=\"Chat\"\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "print(\"Starting Training!\")\n",
    "lossvalues = trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"252.235023pt\" version=\"1.1\" viewBox=\"0 0 362.5625 252.235023\" width=\"362.5625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-02T14:39:29.569065</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.235023 \nL 362.5625 252.235023 \nL 362.5625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 228.356898 \nL 355.3625 228.356898 \nL 355.3625 10.916898 \nL 20.5625 10.916898 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m227e25a194\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.780682\" xlink:href=\"#m227e25a194\" y=\"228.356898\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(32.599432 242.955335)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"86.592641\" xlink:href=\"#m227e25a194\" y=\"228.356898\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(77.048891 242.955335)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"137.4046\" xlink:href=\"#m227e25a194\" y=\"228.356898\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g transform=\"translate(127.86085 242.955335)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"188.21656\" xlink:href=\"#m227e25a194\" y=\"228.356898\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g transform=\"translate(178.67281 242.955335)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.028519\" xlink:href=\"#m227e25a194\" y=\"228.356898\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g transform=\"translate(229.484769 242.955335)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.840478\" xlink:href=\"#m227e25a194\" y=\"228.356898\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <g transform=\"translate(280.296728 242.955335)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"340.652438\" xlink:href=\"#m227e25a194\" y=\"228.356898\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 600 -->\n      <g transform=\"translate(331.108688 242.955335)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m9bde873ea8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m9bde873ea8\" y=\"206.584182\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1 -->\n      <g transform=\"translate(7.2 210.383401)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m9bde873ea8\" y=\"173.986688\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 177.785907)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m9bde873ea8\" y=\"141.389194\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 3 -->\n      <g transform=\"translate(7.2 145.188413)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m9bde873ea8\" y=\"108.791701\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 112.590919)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m9bde873ea8\" y=\"76.194207\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 5 -->\n      <g transform=\"translate(7.2 79.993425)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m9bde873ea8\" y=\"43.596713\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 47.395931)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m9bde873ea8\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 7 -->\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pb9f8068a46)\" d=\"M 35.780682 20.800534 \nL 36.288801 78.377845 \nL 36.796921 99.521597 \nL 37.305041 99.131861 \nL 37.81316 100.054751 \nL 38.32128 103.398229 \nL 38.829399 105.582396 \nL 39.337519 107.010143 \nL 39.845639 109.863395 \nL 40.353758 109.639579 \nL 40.861878 113.75428 \nL 41.369997 113.015673 \nL 42.386237 115.866335 \nL 42.894356 117.340904 \nL 43.402476 114.876513 \nL 43.910595 117.006443 \nL 44.418715 117.090537 \nL 44.926834 119.087957 \nL 45.434954 118.513164 \nL 45.943074 121.973639 \nL 46.451193 122.817252 \nL 46.959313 124.629925 \nL 47.467432 124.40735 \nL 47.975552 126.62278 \nL 48.483672 125.431712 \nL 48.991791 127.356333 \nL 49.499911 131.753371 \nL 50.00803 131.82722 \nL 51.02427 131.366635 \nL 51.532389 132.639089 \nL 52.040509 131.325521 \nL 52.548628 133.97792 \nL 53.056748 134.325016 \nL 53.564868 134.027904 \nL 54.072987 133.313787 \nL 54.581107 135.60411 \nL 55.597346 137.934439 \nL 56.105466 140.579946 \nL 56.613585 140.211901 \nL 57.121705 140.156822 \nL 57.629824 140.578629 \nL 58.137944 142.357783 \nL 58.646064 138.332647 \nL 59.662303 143.866244 \nL 60.170422 143.775778 \nL 60.678542 144.121482 \nL 61.186661 144.894122 \nL 61.694781 145.941089 \nL 62.202901 145.326104 \nL 62.71102 146.834586 \nL 63.727259 148.977631 \nL 64.235379 149.868711 \nL 64.743499 150.163204 \nL 65.251618 151.969339 \nL 65.759738 150.270999 \nL 66.267857 150.538654 \nL 66.775977 151.9056 \nL 67.284097 151.87385 \nL 67.792216 152.704499 \nL 68.300336 152.574786 \nL 68.808455 155.755207 \nL 69.316575 154.831599 \nL 69.824695 154.739158 \nL 70.332814 155.545925 \nL 70.840934 155.698221 \nL 71.349053 158.144722 \nL 71.857173 157.699876 \nL 72.365293 160.297175 \nL 72.873412 158.861793 \nL 73.381532 158.912972 \nL 73.889651 160.818889 \nL 74.397771 159.929274 \nL 74.90589 160.335225 \nL 75.41401 162.246445 \nL 75.92213 162.468914 \nL 76.430249 165.210135 \nL 76.938369 161.98705 \nL 77.446488 163.360948 \nL 77.954608 165.269814 \nL 78.462728 164.577554 \nL 78.970847 165.854322 \nL 79.478967 166.812021 \nL 79.987086 167.146765 \nL 80.495206 167.836418 \nL 81.003326 167.518478 \nL 81.511445 168.332222 \nL 82.019565 170.033423 \nL 82.527684 168.409176 \nL 83.035804 169.607472 \nL 83.543924 169.384834 \nL 84.052043 170.853994 \nL 84.560163 171.34865 \nL 85.068282 170.872276 \nL 85.576402 171.542822 \nL 86.084522 171.736561 \nL 86.592641 171.018265 \nL 87.100761 172.543127 \nL 87.60888 173.191997 \nL 88.117 174.455884 \nL 88.62512 174.22474 \nL 89.133239 173.774307 \nL 89.641359 175.833394 \nL 90.149478 177.304316 \nL 90.657598 174.716671 \nL 91.165717 176.204372 \nL 91.673837 176.513277 \nL 92.181957 177.717219 \nL 92.690076 177.482058 \nL 93.198196 178.056666 \nL 93.706315 179.580317 \nL 94.214435 179.963924 \nL 94.722555 179.534986 \nL 95.230674 179.844417 \nL 95.738794 179.986819 \nL 96.246913 181.614826 \nL 96.755033 181.045922 \nL 97.263153 181.90609 \nL 97.771272 181.376941 \nL 98.279392 182.21846 \nL 98.787511 182.531302 \nL 99.295631 184.305343 \nL 99.803751 184.487871 \nL 100.31187 182.703107 \nL 100.81999 184.188496 \nL 101.328109 184.565848 \nL 101.836229 185.903659 \nL 102.344349 184.588948 \nL 102.852468 184.170348 \nL 103.360588 185.762527 \nL 103.868707 185.626966 \nL 104.376827 188.252489 \nL 104.884947 186.913361 \nL 105.393066 186.929735 \nL 105.901186 187.900443 \nL 106.409305 187.106677 \nL 106.917425 187.447721 \nL 107.425544 187.042945 \nL 107.933664 188.133901 \nL 108.441784 187.590891 \nL 108.949903 189.172701 \nL 109.458023 189.746205 \nL 109.966142 188.952899 \nL 110.982382 191.168004 \nL 111.490501 189.03973 \nL 112.50674 192.524742 \nL 113.01486 191.92512 \nL 113.52298 191.906795 \nL 114.031099 192.442005 \nL 114.539219 192.27676 \nL 115.047338 192.943702 \nL 115.555458 192.646041 \nL 116.063578 193.486282 \nL 116.571697 192.752257 \nL 117.079817 193.328469 \nL 117.587936 195.39182 \nL 118.096056 194.904392 \nL 119.112295 196.160242 \nL 119.620415 194.425358 \nL 120.128534 195.057206 \nL 120.636654 194.936876 \nL 121.144773 196.091371 \nL 121.652893 198.06966 \nL 122.161013 196.685579 \nL 122.669132 197.130468 \nL 123.177252 197.144222 \nL 123.685371 195.988387 \nL 124.193491 196.987127 \nL 124.701611 197.641361 \nL 125.20973 197.18992 \nL 125.71785 197.18236 \nL 126.225969 196.815498 \nL 126.734089 197.227059 \nL 127.242209 198.181171 \nL 127.750328 200.025349 \nL 128.258448 200.004827 \nL 128.766567 199.852514 \nL 129.274687 200.334548 \nL 129.782807 200.243018 \nL 130.290926 199.7795 \nL 130.799046 200.02975 \nL 131.307165 200.814349 \nL 131.815285 200.019951 \nL 132.323405 201.201403 \nL 132.831524 200.857573 \nL 133.339644 199.963423 \nL 133.847763 201.601701 \nL 134.864003 200.778883 \nL 135.372122 201.444906 \nL 135.880242 201.475354 \nL 136.388361 202.623916 \nL 136.896481 202.032249 \nL 137.91272 203.817364 \nL 138.42084 201.623226 \nL 138.928959 202.497554 \nL 139.437079 203.775369 \nL 139.945198 203.268571 \nL 140.453318 203.104627 \nL 140.961438 204.790579 \nL 141.469557 203.809846 \nL 141.977677 204.80903 \nL 142.485796 203.590041 \nL 142.993916 203.41458 \nL 143.502036 204.672426 \nL 144.010155 204.662538 \nL 144.518275 205.334337 \nL 145.026394 205.617917 \nL 145.534514 204.709427 \nL 146.042634 205.006208 \nL 146.550753 206.550817 \nL 147.058873 205.510666 \nL 147.566992 204.924534 \nL 148.075112 205.184501 \nL 148.583232 206.143851 \nL 149.091351 205.407605 \nL 149.599471 206.000644 \nL 150.10759 206.254704 \nL 150.61571 205.099143 \nL 151.123829 205.529848 \nL 151.631949 206.601978 \nL 152.140069 206.596579 \nL 152.648188 206.304084 \nL 153.664427 206.464204 \nL 154.172547 207.575911 \nL 154.680667 207.891329 \nL 155.188786 206.954558 \nL 155.696906 206.292633 \nL 156.205025 207.855657 \nL 156.713145 207.319801 \nL 157.221265 207.360497 \nL 157.729384 208.002866 \nL 158.745623 208.519116 \nL 159.761863 208.015533 \nL 160.269982 208.55238 \nL 161.286221 209.362215 \nL 161.794341 208.413138 \nL 162.302461 209.005139 \nL 162.81058 208.352584 \nL 163.3187 208.147953 \nL 163.826819 208.659065 \nL 164.334939 208.162035 \nL 164.843059 209.09454 \nL 165.351178 208.420681 \nL 165.859298 208.937503 \nL 166.367417 209.777369 \nL 166.875537 208.777868 \nL 167.383656 209.576346 \nL 167.891776 208.857398 \nL 168.399896 209.263999 \nL 168.908015 208.987877 \nL 169.416135 209.809707 \nL 169.924254 208.69695 \nL 170.432374 209.101515 \nL 170.940494 210.075584 \nL 171.448613 210.352705 \nL 171.956733 210.296846 \nL 172.464852 210.383578 \nL 172.972972 209.887362 \nL 173.481092 209.849863 \nL 174.497331 210.208095 \nL 175.00545 209.877877 \nL 175.51357 209.163601 \nL 176.02169 209.697196 \nL 176.529809 209.733737 \nL 177.037929 211.539324 \nL 177.546048 211.671418 \nL 178.054168 209.917577 \nL 178.562288 210.046745 \nL 179.070407 211.162619 \nL 179.578527 210.983493 \nL 180.086646 210.989108 \nL 180.594766 210.556727 \nL 181.102885 211.686933 \nL 181.611005 211.267167 \nL 182.119125 210.621104 \nL 182.627244 211.334001 \nL 183.135364 212.50792 \nL 183.643483 211.15239 \nL 184.151603 211.817947 \nL 184.659723 211.961765 \nL 185.167842 211.59971 \nL 185.675962 212.391782 \nL 186.184081 210.415684 \nL 186.692201 211.292922 \nL 187.200321 211.65185 \nL 187.70844 211.084986 \nL 188.21656 211.086931 \nL 188.724679 211.264765 \nL 189.740919 212.316742 \nL 190.249038 211.654777 \nL 190.757158 211.924179 \nL 191.265277 212.340136 \nL 191.773397 211.932933 \nL 192.281517 212.441015 \nL 192.789636 212.423673 \nL 193.297756 212.707349 \nL 193.805875 211.912039 \nL 194.313995 213.470429 \nL 194.822115 212.471276 \nL 195.330234 213.602382 \nL 196.346473 212.255219 \nL 196.854593 212.633863 \nL 197.362712 213.187636 \nL 198.378952 212.469671 \nL 198.887071 212.963587 \nL 199.395191 211.743469 \nL 199.90331 212.718909 \nL 200.41143 212.444308 \nL 200.91955 214.248379 \nL 201.427669 212.928862 \nL 201.935789 212.449265 \nL 202.443908 212.710439 \nL 202.952028 212.761709 \nL 203.460148 213.024965 \nL 203.968267 213.629163 \nL 204.476387 213.542089 \nL 204.984506 214.458398 \nL 205.492626 212.751592 \nL 206.000746 212.131286 \nL 206.508865 213.453751 \nL 207.016985 213.693489 \nL 208.033224 213.296991 \nL 208.541344 214.277391 \nL 209.049463 214.705759 \nL 209.557583 214.493684 \nL 210.573822 213.804621 \nL 211.081941 213.952031 \nL 212.098181 213.527831 \nL 212.6063 213.873356 \nL 213.622539 213.749141 \nL 214.130659 214.567145 \nL 215.146898 214.019655 \nL 215.655018 214.695856 \nL 216.163137 214.919536 \nL 216.671257 214.254694 \nL 217.179377 214.064551 \nL 217.687496 214.289672 \nL 218.195616 214.059622 \nL 218.703735 214.679875 \nL 219.211855 213.71337 \nL 219.719975 214.837896 \nL 220.228094 213.241125 \nL 220.736214 214.218862 \nL 221.244333 214.201215 \nL 221.752453 215.645492 \nL 222.260573 214.89688 \nL 222.768692 214.560852 \nL 223.276812 214.824359 \nL 223.784931 214.855543 \nL 224.293051 214.151038 \nL 224.801171 215.159777 \nL 225.30929 214.230534 \nL 225.81741 214.725074 \nL 226.325529 215.397528 \nL 226.833649 214.503234 \nL 227.341768 214.555305 \nL 227.849888 215.508778 \nL 228.358008 214.846623 \nL 228.866127 215.319764 \nL 229.374247 214.793373 \nL 229.882366 214.773492 \nL 230.390486 215.097042 \nL 230.898606 215.941357 \nL 231.406725 214.665079 \nL 231.914845 215.803084 \nL 232.422964 214.69849 \nL 232.931084 214.524594 \nL 233.439204 214.66838 \nL 233.947323 213.54546 \nL 234.455443 213.982934 \nL 234.963562 214.050044 \nL 235.471682 212.670579 \nL 235.979802 213.314769 \nL 236.487921 213.685563 \nL 236.996041 213.616576 \nL 237.50416 213.690492 \nL 238.01228 214.087232 \nL 238.5204 214.121468 \nL 239.028519 213.676481 \nL 239.536639 214.601189 \nL 240.044758 214.419234 \nL 240.552878 213.243489 \nL 241.060997 214.212766 \nL 241.569117 215.424583 \nL 242.077237 215.218893 \nL 242.585356 214.743959 \nL 243.093476 216.060576 \nL 243.601595 214.485179 \nL 244.109715 214.262985 \nL 244.617835 215.003616 \nL 245.634074 215.610743 \nL 246.142193 215.337398 \nL 246.650313 216.226208 \nL 247.158433 215.049997 \nL 247.666552 215.703269 \nL 248.682791 214.302464 \nL 249.190911 215.145104 \nL 249.699031 215.754665 \nL 251.223389 214.594119 \nL 251.731509 215.332572 \nL 252.239629 214.749967 \nL 252.747748 215.720409 \nL 253.255868 215.392147 \nL 253.763987 214.743422 \nL 254.272107 216.303552 \nL 254.780227 216.141238 \nL 255.288346 216.181612 \nL 255.796466 215.662363 \nL 256.304585 215.624533 \nL 256.812705 215.001028 \nL 257.320824 215.520374 \nL 257.828944 216.219963 \nL 258.337064 215.826084 \nL 258.845183 215.824251 \nL 259.353303 215.268952 \nL 259.861422 215.31636 \nL 260.369542 215.937931 \nL 260.877662 215.733951 \nL 261.385781 216.05474 \nL 261.893901 215.729201 \nL 262.40202 216.507931 \nL 262.91014 216.057885 \nL 263.41826 216.355104 \nL 264.434499 215.833921 \nL 264.942618 215.588044 \nL 265.450738 215.728442 \nL 265.958858 214.523853 \nL 266.466977 215.590926 \nL 266.975097 217.123451 \nL 267.483216 215.94967 \nL 267.991336 216.910611 \nL 268.499456 215.366517 \nL 269.007575 216.219097 \nL 269.515695 215.590867 \nL 270.023814 217.187286 \nL 270.531934 216.172534 \nL 271.040053 215.548597 \nL 271.548173 217.168774 \nL 272.056293 215.93841 \nL 272.564412 216.131819 \nL 273.072532 216.188275 \nL 273.580651 216.407475 \nL 274.088771 216.821314 \nL 274.596891 215.788945 \nL 275.10501 215.980439 \nL 276.121249 215.551823 \nL 276.629369 216.203907 \nL 277.137489 215.828323 \nL 277.645608 217.1941 \nL 278.153728 215.56936 \nL 278.661847 216.705561 \nL 279.169967 216.35938 \nL 279.678087 216.673111 \nL 280.186206 217.129224 \nL 281.202445 216.618837 \nL 281.710565 217.180874 \nL 282.218685 217.991283 \nL 282.726804 217.246362 \nL 283.234924 217.313124 \nL 283.743043 216.295203 \nL 284.251163 217.223322 \nL 284.759283 217.192633 \nL 285.267402 215.945571 \nL 285.775522 216.341319 \nL 286.283641 217.48161 \nL 286.791761 217.229762 \nL 288.31612 217.116098 \nL 288.824239 216.666872 \nL 289.332359 216.980928 \nL 290.856718 216.717272 \nL 291.364837 216.399868 \nL 291.872957 217.272105 \nL 292.381076 217.466801 \nL 292.889196 216.712908 \nL 293.397316 217.234323 \nL 293.905435 216.574217 \nL 294.413555 216.95043 \nL 294.921674 216.024468 \nL 295.429794 216.699336 \nL 295.937914 216.174493 \nL 296.446033 216.13969 \nL 296.954153 217.07747 \nL 297.462272 216.750841 \nL 297.970392 217.520405 \nL 298.478512 216.69289 \nL 298.986631 217.421224 \nL 299.494751 217.43841 \nL 300.00287 217.038585 \nL 300.51099 216.788477 \nL 301.01911 216.737496 \nL 301.527229 218.057352 \nL 302.035349 217.341113 \nL 302.543468 216.260969 \nL 303.559707 217.099168 \nL 304.067827 216.327071 \nL 304.575947 216.762095 \nL 305.592186 217.183414 \nL 306.100305 216.050994 \nL 306.608425 216.99132 \nL 307.116545 216.225967 \nL 307.624664 216.088 \nL 308.132784 216.890777 \nL 308.640903 216.211134 \nL 309.657143 217.944259 \nL 310.165262 216.671438 \nL 310.673382 216.935847 \nL 311.181501 217.666315 \nL 312.197741 217.069659 \nL 312.70586 217.02836 \nL 313.21398 217.640617 \nL 313.722099 217.268706 \nL 314.230219 217.947665 \nL 314.738339 217.053727 \nL 315.246458 217.661985 \nL 315.754578 217.565788 \nL 316.262697 217.354667 \nL 316.770817 218.046892 \nL 317.278936 216.437845 \nL 317.787056 217.835439 \nL 318.295176 216.410306 \nL 318.803295 216.639105 \nL 319.311415 217.520875 \nL 319.819534 217.93617 \nL 320.327654 217.632953 \nL 320.835774 218.05843 \nL 321.343893 217.820468 \nL 321.852013 217.986184 \nL 322.360132 216.820763 \nL 322.868252 217.709073 \nL 323.376372 217.768772 \nL 323.884491 217.191682 \nL 324.90073 218.189542 \nL 325.40885 217.07328 \nL 325.91697 217.541551 \nL 326.425089 217.412294 \nL 326.933209 218.127276 \nL 327.441328 216.593697 \nL 327.949448 217.575871 \nL 328.457568 216.855659 \nL 328.965687 217.449586 \nL 329.473807 218.464275 \nL 329.981926 216.70751 \nL 330.490046 217.224812 \nL 330.998166 218.323553 \nL 331.506285 217.806796 \nL 332.014405 218.452618 \nL 332.522524 218.309166 \nL 333.030644 217.107202 \nL 333.538763 217.387103 \nL 334.046883 217.200216 \nL 334.555003 218.473261 \nL 335.063122 218.073076 \nL 335.571242 217.256155 \nL 336.079361 217.661205 \nL 336.587481 217.405357 \nL 337.095601 217.983026 \nL 338.11184 218.092979 \nL 338.619959 217.783794 \nL 339.128079 218.322828 \nL 339.636199 217.905685 \nL 340.144318 217.089383 \nL 340.144318 217.089383 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 228.356898 \nL 20.5625 10.916898 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 355.3625 228.356898 \nL 355.3625 10.916898 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 228.356898 \nL 355.3625 228.356898 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 10.916898 \nL 355.3625 10.916898 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb9f8068a46\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"20.5625\" y=\"10.916898\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lossvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n0 0.0 0.0\n0\n0\n0\n0\n0.06295853427918728\n0\n0\n0\n0\n0.3333333333333333\n0\n0\n0\n0.3333333333333333\n0.5\n0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "('haha',)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3367a728010e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#   print(output_words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#   print(templist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mscore1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msmoothing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchencherry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mscore2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmoothing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchencherry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36msentence_bleu\u001b[0;34m(references, hypothesis, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[1;32m     98\u001b[0m     return corpus_bleu(\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_reweigh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# denominator for the corpus-level modified precision.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mp_numerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mp_denominators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mmodified_precision\u001b[0;34m(references, hypothesis, n)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# Assigns the intersection between hypothesis and references' counts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     clipped_counts = {\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mngram\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     }\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# Assigns the intersection between hypothesis and references' counts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     clipped_counts = {\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mngram\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     }\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('haha',)"
     ]
    }
   ],
   "source": [
    "#  Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "gram1_bleu_score = []\n",
    "gram2_bleu_score = []\n",
    "\n",
    "# print(testpairs)\n",
    "\n",
    "for i in range(0,len(testpairs),1):\n",
    "  \n",
    "  input_sentence = testpairs[i][0]\n",
    "  \n",
    "  reference = testpairs[i][1:]\n",
    "  templist = []\n",
    "  for k in range(len(reference)):\n",
    "    if(reference[k]!=''):\n",
    "      temp = reference[k].split(' ')\n",
    "      templist.append(temp)\n",
    "  \n",
    "  \n",
    "  input_sentence = normalizeString(input_sentence)\n",
    "  output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "  output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "  chencherry = SmoothingFunction()\n",
    "#   print(output_words)\n",
    "#   print(templist)\n",
    "  score1 = sentence_bleu(templist,output_words,weights=(1, 0, 0, 0) ,smoothing_function=chencherry.method1)\n",
    "  score2 = sentence_bleu(templist,output_words,weights=(0.5, 0.5, 0, 0),smoothing_function=chencherry.method1) \n",
    "  print(score1)\n",
    "  gram1_bleu_score.append(score1)\n",
    "  gram2_bleu_score.append(score2)\n",
    "  if i%1000 == 0:\n",
    "    print(i,sum(gram1_bleu_score)/len(gram1_bleu_score),sum(gram2_bleu_score)/len(gram2_bleu_score))\n",
    "# print(\"Total Bleu Score for 1 grams on testing pairs: \", sum(gram1_bleu_score)/len(gram1_bleu_score) )  \n",
    "# print(\"Total Bleu Score for 2 grams on testing pairs: \", sum(gram2_bleu_score)/len(gram2_bleu_score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "]\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)\n",
    "# input\n",
    "# Hi, how are you?\n",
    "# What\n",
    "# I don't understand you\n",
    "# hmm, good bye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, decoder_hidden, last_idx=SOS_token, sentence_idxes=[], sentence_scores=[]):\n",
    "        if(len(sentence_idxes) != len(sentence_scores)):\n",
    "            raise ValueError(\"length of indexes and scores should be the same\")\n",
    "        self.decoder_hidden = decoder_hidden\n",
    "        self.last_idx = last_idx\n",
    "        self.sentence_idxes =  sentence_idxes\n",
    "        self.sentence_scores = sentence_scores\n",
    "\n",
    "    def avgScore(self):\n",
    "        if len(self.sentence_scores) == 0:\n",
    "            raise ValueError(\"Calculate average score of sentence, but got no word\")\n",
    "        # return mean of sentence_score\n",
    "        return sum(self.sentence_scores) / len(self.sentence_scores)\n",
    "\n",
    "    def addTopk(self, topi, topv, decoder_hidden, beam_size, voc):\n",
    "        topv = torch.log(topv)\n",
    "        terminates, sentences = [], []\n",
    "        for i in range(beam_size):\n",
    "            if topi[0][i] == EOS_token:\n",
    "                terminates.append(([voc.index2word[idx.item()] for idx in self.sentence_idxes] + ['<EOS>'],\n",
    "                                   self.avgScore())) \n",
    "                continue\n",
    "            idxes = self.sentence_idxes[:] \n",
    "            scores = self.sentence_scores[:] \n",
    "            idxes.append(topi[0][i])\n",
    "            scores.append(topv[0][i])\n",
    "            sentences.append(Sentence(decoder_hidden, topi[0][i], idxes, scores))\n",
    "        return terminates, sentences\n",
    "\n",
    "    def toWordScore(self, voc):\n",
    "        \n",
    "        words = []\n",
    "        for i in range(len(self.sentence_idxes)):\n",
    "            if self.sentence_idxes[i] == EOS_token:\n",
    "                words.append('<EOS>')\n",
    "            else:\n",
    "                words.append(voc.index2word[self.sentence_idxes[i].item()])\n",
    "       \n",
    "        if self.sentence_idxes[-1] != EOS_token:\n",
    "            words.append('<EOS>')\n",
    "        return (words, self.avgScore())\n",
    "\n",
    "    def __repr__(self):\n",
    "        res = f\"Sentence with indices {self.sentence_idxes} \"\n",
    "        res += f\"and scores {self.sentence_scores}\"\n",
    "        return res\n",
    "def beam_decode(decoder, decoder_hidden, encoder_outputs, voc, beam_size, max_length=MAX_LENGTH):\n",
    "    terminal_sentences, prev_top_sentences, next_top_sentences = [], [], []\n",
    "    prev_top_sentences.append(Sentence(decoder_hidden))\n",
    "    for i in range(max_length):\n",
    "        \n",
    "        for sentence in prev_top_sentences:\n",
    "            decoder_input = torch.LongTensor([[sentence.last_idx]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "\n",
    "            decoder_hidden = sentence.decoder_hidden\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(beam_size)\n",
    "            term, top = sentence.addTopk(topi, topv, decoder_hidden, beam_size, voc)\n",
    "            terminal_sentences.extend(term)\n",
    "            next_top_sentences.extend(top)\n",
    "           \n",
    "        \n",
    "        next_top_sentences.sort(key=lambda s: s.avgScore(), reverse=True)\n",
    "        prev_top_sentences = next_top_sentences[:beam_size]\n",
    "        next_top_sentences = []\n",
    "        \n",
    "\n",
    "    terminal_sentences += [sentence.toWordScore(voc) for sentence in prev_top_sentences]\n",
    "    terminal_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    n = min(len(terminal_sentences), 15)\n",
    "    return terminal_sentences[:n]\n",
    "\n",
    "\n",
    "\n",
    "class BeamSearchDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, voc, beam_size=10):\n",
    "        super(BeamSearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.voc = voc\n",
    "        self.beam_size = beam_size\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n",
    "        \n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        sentences = beam_decode(self.decoder, decoder_hidden, encoder_outputs, self.voc, self.beam_size, max_length)\n",
    "        \n",
    "        \n",
    "        all_tokens = [torch.tensor(self.voc.word2index.get(w, 0)) for w in sentences[0][0]]\n",
    "        return all_tokens, None\n",
    "\n",
    "    def __str__(self):\n",
    "        res = f\"BeamSearchDecoder with beam size {self.beam_size}\"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "\n",
    "hidden_size = 512\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 4\n",
    "dropout = 0.5\n",
    "batch_size = 256 \n",
    "loadFilename = None\n",
    "\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "save_dir = 'content/'\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 6000\n",
    "print_every = 10\n",
    "save_every = 2000\n",
    "loadFilename = None\n",
    "corpus_name=\"Chat\"\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "print(\"Starting Training!\")\n",
    "lossvalues = trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lossvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "############################################################################\n",
    "# Difference between greedy search and beam search is here\n",
    "\n",
    "# greedy search\n",
    "# searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# beam search\n",
    "searcher = BeamSearchDecoder(encoder, decoder, voc, 10)\n",
    "############################################################################\n",
    "gram1_bleu_score = []\n",
    "gram2_bleu_score = []\n",
    "for i in range(0,len(testpairs),1):\n",
    "  \n",
    "  input_sentence = testpairs[i][0]\n",
    "  \n",
    "  reference = testpairs[i][1:]\n",
    "  templist = []\n",
    "  for k in range(len(reference)):\n",
    "    if(reference[k]!=''):\n",
    "      temp = reference[k].split(' ')\n",
    "      templist.append(temp)\n",
    "  \n",
    "  \n",
    "  input_sentence = normalizeString(input_sentence)\n",
    "  output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "  output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "  chencherry = SmoothingFunction()\n",
    "  score1 = sentence_bleu(templist,output_words,weights=(1, 0, 0, 0) ,smoothing_function=chencherry.method1)\n",
    "  score2 = sentence_bleu(templist,output_words,weights=(0.5, 0.5, 0, 0),smoothing_function=chencherry.method1) \n",
    "  gram1_bleu_score.append(score1)\n",
    "  gram2_bleu_score.append(score2)\n",
    "  if i%1000 == 0:\n",
    "    print(i,sum(gram1_bleu_score)/len(gram1_bleu_score),sum(gram2_bleu_score)/len(gram2_bleu_score))\n",
    "print(\"Total Bleu Score for 1 grams on testing pairs: \", sum(gram1_bleu_score)/len(gram1_bleu_score))  \n",
    "print(\"Total Bleu Score for 2 grams on testing pairs: \", sum(gram2_bleu_score)/len(gram2_bleu_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "searcher = BeamSearchDecoder(encoder, decoder, voc, 10)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  }
 ]
}