{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab 8 - st121413"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Visdom\n",
    "\n",
    "The screenshot below is the prove that my visdom server is working.\n",
    "\n",
    "![alt text](./screenshot/visdom.png)\n",
    "\n",
    "Explaining the 8-grid pictures are as follow\n",
    "\n",
    "- real_A: Original input photo\n",
    "- fake_B: The result from generator A when input is real_A <code>G_A(real_A)</code>\n",
    "- rec_A: The result reconstructing real_A back from fake_B <code>G_B(G_A(real_A)) = G_B(fake_b)</code>\n",
    "- idt_B: The result from generator B when input is real A <code>G_B(real_A)</code>\n",
    "\n",
    "Same case for second row\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To get this lab runningm I just need to follow the instruction given in the lab manual"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n",
    "# !pip3 install dominate visdom"
   ]
  },
  {
   "source": [
    "## 1. horse 2 zebra\n",
    "\n",
    "This task is one of the example in the github. Follow the github tutorial or lab manual both fine. \n",
    "\n",
    "1. Download the dataset\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd pytorch-CycleGAN-and-pix2pix\n",
    "# !./datasets/download_cyclegan_dataset.sh horse2zebra"
   ]
  },
  {
   "source": [
    "Sneak peak at the downloaded dataset. It structured in this manner.\n",
    "\n",
    "- datasets\n",
    "  - horse2zebra\n",
    "    - testA\n",
    "    - testB\n",
    "    - trainA\n",
    "    - trainB\n",
    "\n",
    "Folder *A contains picture of horse(s) and *B contains zebra/(s)\n",
    "\n",
    "2. Train cycalGAN using the following comands"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd pytorch-CycleGAN-and-pix2pix\n",
    "# !unset http_proxy\n",
    "# !unset https_proxy\n",
    "# !nohup python3 -u train.py --dataroot ./datasets/horse2zebra --gpu_ids 0 --name horse2zebra_cyclegan --model cycle_gan > nohup_hourse2zebra.out"
   ]
  },
  {
   "source": [
    "In the \"server behind proxy\" setup, we need to unset the proxy from the environment. If not, python code will try to ask the proxy for \"http://localhost:8097\" which unknown to the proxy server. (or find another way to escape http://localhost from proxy)\n",
    "\n",
    "Below is what printed out from the training script."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Options ---------------\n",
    "#                batch_size: 1                             \n",
    "#                     beta1: 0.5                           \n",
    "#           checkpoints_dir: ./checkpoints                 \n",
    "#            continue_train: False                         \n",
    "#                 crop_size: 256                           \n",
    "#                  dataroot: ./datasets/horse2zebra        \t[default: None]\n",
    "#              dataset_mode: unaligned                     \n",
    "#                 direction: AtoB                          \n",
    "#               display_env: main                          \n",
    "#              display_freq: 400                           \n",
    "#                display_id: 1                             \n",
    "#             display_ncols: 4                             \n",
    "#              display_port: 8097                          \n",
    "#            display_server: http://localhost              \n",
    "#           display_winsize: 256                           \n",
    "#                     epoch: latest                        \n",
    "#               epoch_count: 1                             \n",
    "#                  gan_mode: lsgan                         \n",
    "#                   gpu_ids: 0                             \n",
    "#                 init_gain: 0.02                          \n",
    "#                 init_type: normal                        \n",
    "#                  input_nc: 3                             \n",
    "#                   isTrain: True                          \t[default: None]\n",
    "#                  lambda_A: 10.0                          \n",
    "#                  lambda_B: 10.0                          \n",
    "#           lambda_identity: 0.5                           \n",
    "#                 load_iter: 0                             \t[default: 0]\n",
    "#                 load_size: 286                           \n",
    "#                        lr: 0.0002                        \n",
    "#            lr_decay_iters: 50                            \n",
    "#                 lr_policy: linear                        \n",
    "#          max_dataset_size: inf                           \n",
    "#                     model: cycle_gan                     \n",
    "#                  n_epochs: 100                           \n",
    "#            n_epochs_decay: 100                           \n",
    "#                n_layers_D: 3                             \n",
    "#                      name: horse2zebra_cyclegan          \t[default: experiment_name]\n",
    "#                       ndf: 64                            \n",
    "#                      netD: basic                         \n",
    "#                      netG: resnet_9blocks                \n",
    "#                       ngf: 64                            \n",
    "#                no_dropout: True                          \n",
    "#                   no_flip: False                         \n",
    "#                   no_html: False                         \n",
    "#                      norm: instance                      \n",
    "#               num_threads: 4                             \n",
    "#                 output_nc: 3                             \n",
    "#                     phase: train                         \n",
    "#                 pool_size: 50                            \n",
    "#                preprocess: resize_and_crop               \n",
    "#                print_freq: 100                           \n",
    "#              save_by_iter: False                         \n",
    "#           save_epoch_freq: 5                             \n",
    "#          save_latest_freq: 5000                          \n",
    "#            serial_batches: False                         \n",
    "#                    suffix:                               \n",
    "#          update_html_freq: 1000                          \n",
    "#                   verbose: False                         \n",
    "# ----------------- End -------------------\n",
    "# dataset [UnalignedDataset] was created\n",
    "# The number of training images = 1334\n",
    "# initialize network with normal\n",
    "# initialize network with normal\n",
    "# initialize network with normal\n",
    "# initialize network with normal\n",
    "# model [CycleGANModel] was created\n",
    "# ---------- Networks initialized -------------\n",
    "# [Network G_A] Total number of parameters : 11.378 M\n",
    "# [Network G_B] Total number of parameters : 11.378 M\n",
    "# [Network D_A] Total number of parameters : 2.765 M\n",
    "# [Network D_B] Total number of parameters : 2.765 M\n",
    "# -----------------------------------------------\n",
    "# /usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.3) or chardet (3.0.4) doesn't match a supported version!\n",
    "#   RequestsDependencyWarning)\n",
    "# Setting up a new session...\n",
    "# create web directory ./checkpoints/horse2zebra_cyclegan/web...\n",
    "# /usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
    "#   \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
    "# learning rate 0.0002000 -> 0.0002000"
   ]
  },
  {
   "source": [
    "Below is an example report from the training script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (epoch: 1, iters: 100, time: 0.269, data: 0.223) D_A: 0.516 G_A: 0.465 cycle_A: 2.570 idt_A: 0.816 D_B: 0.425 G_B: 0.571 cycle_B: 1.955 idt_B: 1.180 \n",
    "# (epoch: 1, iters: 200, time: 0.271, data: 0.001) D_A: 0.287 G_A: 0.218 cycle_A: 2.726 idt_A: 0.850 D_B: 0.280 G_B: 0.276 cycle_B: 1.849 idt_B: 1.343 \n",
    "# (epoch: 1, iters: 300, time: 0.274, data: 0.001) D_A: 0.328 G_A: 0.445 cycle_A: 2.792 idt_A: 0.851 D_B: 0.273 G_B: 0.371 cycle_B: 1.994 idt_B: 1.234 \n",
    "# (epoch: 1, iters: 400, time: 0.657, data: 0.001) D_A: 0.316 G_A: 0.272 cycle_A: 1.644 idt_A: 1.501 D_B: 0.377 G_B: 0.078 cycle_B: 2.981 idt_B: 0.787 \n",
    "# (epoch: 1, iters: 500, time: 0.278, data: 0.001) D_A: 0.334 G_A: 0.147 cycle_A: 1.808 idt_A: 0.972 D_B: 0.379 G_B: 0.686 cycle_B: 2.022 idt_B: 0.776 \n",
    "# (epoch: 1, iters: 600, time: 0.278, data: 0.001) D_A: 0.325 G_A: 0.454 cycle_A: 2.329 idt_A: 1.201 D_B: 0.315 G_B: 0.297 cycle_B: 2.550 idt_B: 1.160 \n",
    "# (epoch: 1, iters: 700, time: 0.286, data: 0.001) D_A: 0.174 G_A: 0.388 cycle_A: 2.788 idt_A: 1.446 D_B: 0.179 G_B: 0.588 cycle_B: 3.010 idt_B: 1.005 \n",
    "# (epoch: 1, iters: 800, time: 0.417, data: 0.001) D_A: 0.180 G_A: 0.372 cycle_A: 2.465 idt_A: 0.916 D_B: 0.316 G_B: 0.522 cycle_B: 1.902 idt_B: 0.830 \n",
    "# (epoch: 1, iters: 900, time: 0.287, data: 0.001) D_A: 0.211 G_A: 0.320 cycle_A: 4.017 idt_A: 0.885 D_B: 0.225 G_B: 0.551 cycle_B: 1.917 idt_B: 1.389 \n",
    "# (epoch: 1, iters: 1000, time: 0.286, data: 0.001) D_A: 0.251 G_A: 0.161 cycle_A: 2.847 idt_A: 1.350 D_B: 0.221 G_B: 0.436 cycle_B: 2.746 idt_B: 1.292 \n",
    "# (epoch: 1, iters: 1100, time: 0.296, data: 0.001) D_A: 0.204 G_A: 0.548 cycle_A: 2.252 idt_A: 1.531 D_B: 0.284 G_B: 0.355 cycle_B: 3.095 idt_B: 1.049 \n",
    "# (epoch: 1, iters: 1200, time: 0.423, data: 0.001) D_A: 0.284 G_A: 0.451 cycle_A: 2.065 idt_A: 0.945 D_B: 0.179 G_B: 0.347 cycle_B: 1.690 idt_B: 0.872 \n",
    "# (epoch: 1, iters: 1300, time: 0.290, data: 0.001) D_A: 0.346 G_A: 0.379 cycle_A: 1.353 idt_A: 1.002 D_B: 0.345 G_B: 0.358 cycle_B: 2.060 idt_B: 0.733 \n",
    "# End of epoch 1 / 200 \t Time Taken: 375 sec\n",
    "# learning rate 0.0002000 -> 0.0002000"
   ]
  },
  {
   "source": [
    "Each line report a loss.\n",
    " - D_A     is loss of discriminator A\n",
    " - G_A     is loss of Generator A\n",
    " - cycle_A is cycle loss of A\n",
    " - idt_a   is identity loss of A\n",
    "\n",
    "Same case for *_B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (epoch: 200, iters: 34, time: 0.276, data: 0.001) D_A: 0.103 G_A: 0.532 cycle_A: 0.613 idt_A: 0.229 D_B: 0.107 G_B: 0.637 cycle_B: 0.747 idt_B: 0.213 \n",
    "# (epoch: 200, iters: 134, time: 1.413, data: 0.001) D_A: 0.101 G_A: 0.464 cycle_A: 0.662 idt_A: 0.278 D_B: 0.064 G_B: 0.675 cycle_B: 0.571 idt_B: 0.209 \n",
    "# (epoch: 200, iters: 234, time: 0.275, data: 0.001) D_A: 0.072 G_A: 0.561 cycle_A: 0.656 idt_A: 0.326 D_B: 0.145 G_B: 0.532 cycle_B: 0.889 idt_B: 0.240 \n",
    "# (epoch: 200, iters: 334, time: 0.275, data: 0.001) D_A: 0.043 G_A: 0.461 cycle_A: 0.654 idt_A: 0.242 D_B: 0.090 G_B: 0.384 cycle_B: 0.556 idt_B: 0.201 \n",
    "# (epoch: 200, iters: 434, time: 0.275, data: 0.001) D_A: 0.070 G_A: 0.636 cycle_A: 0.440 idt_A: 0.206 D_B: 0.100 G_B: 0.581 cycle_B: 0.573 idt_B: 0.144 \n",
    "# (epoch: 200, iters: 534, time: 1.431, data: 0.001) D_A: 0.048 G_A: 0.647 cycle_A: 0.713 idt_A: 0.179 D_B: 0.290 G_B: 0.537 cycle_B: 0.579 idt_B: 0.277 \n",
    "# (epoch: 200, iters: 634, time: 0.276, data: 0.001) D_A: 0.084 G_A: 0.475 cycle_A: 0.749 idt_A: 0.248 D_B: 0.063 G_B: 0.688 cycle_B: 0.782 idt_B: 0.226 \n",
    "# (epoch: 200, iters: 734, time: 0.276, data: 0.001) D_A: 0.107 G_A: 0.455 cycle_A: 0.532 idt_A: 0.208 D_B: 0.104 G_B: 0.550 cycle_B: 0.770 idt_B: 0.170 \n",
    "# (epoch: 200, iters: 834, time: 0.274, data: 0.001) D_A: 0.039 G_A: 0.676 cycle_A: 0.491 idt_A: 0.193 D_B: 0.258 G_B: 0.638 cycle_B: 0.652 idt_B: 0.174 \n",
    "# (epoch: 200, iters: 934, time: 0.417, data: 0.001) D_A: 0.181 G_A: 0.551 cycle_A: 0.602 idt_A: 0.164 D_B: 0.188 G_B: 0.498 cycle_B: 0.526 idt_B: 0.188 \n",
    "# (epoch: 200, iters: 1034, time: 0.275, data: 0.001) D_A: 0.134 G_A: 0.484 cycle_A: 0.635 idt_A: 0.192 D_B: 0.096 G_B: 0.544 cycle_B: 0.510 idt_B: 0.228 \n",
    "# (epoch: 200, iters: 1134, time: 0.275, data: 0.001) D_A: 0.150 G_A: 1.109 cycle_A: 0.539 idt_A: 0.210 D_B: 0.095 G_B: 0.484 cycle_B: 0.482 idt_B: 0.211 \n",
    "# (epoch: 200, iters: 1234, time: 0.275, data: 0.001) D_A: 0.036 G_A: 0.727 cycle_A: 0.538 idt_A: 0.240 D_B: 0.097 G_B: 0.597 cycle_B: 0.701 idt_B: 0.138 \n",
    "# (epoch: 200, iters: 1334, time: 0.428, data: 0.001) D_A: 0.113 G_A: 0.469 cycle_A: 0.669 idt_A: 0.156 D_B: 0.230 G_B: 0.462 cycle_B: 0.512 idt_B: 0.182 \n",
    "# End of epoch 200 / 200 \t Time Taken: 372 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ python3 test.py --dataroot ./datasets/horse2zebra --gpu_ids 1 --name horse2zebra_cyclegan --model cycle_gan\n",
    "# ----------------- Options ---------------\n",
    "#              aspect_ratio: 1.0                           \n",
    "#                batch_size: 1                             \n",
    "#           checkpoints_dir: ./checkpoints                 \n",
    "#                 crop_size: 256                           \n",
    "#                  dataroot: ./datasets/horse2zebra        \t[default: None]\n",
    "#              dataset_mode: unaligned                     \n",
    "#                 direction: AtoB                          \n",
    "#           display_winsize: 256                           \n",
    "#                     epoch: latest                        \n",
    "#                      eval: False                         \n",
    "#                   gpu_ids: 1                             \t[default: 0]\n",
    "#                 init_gain: 0.02                          \n",
    "#                 init_type: normal                        \n",
    "#                  input_nc: 3                             \n",
    "#                   isTrain: False                         \t[default: None]\n",
    "#                 load_iter: 0                             \t[default: 0]\n",
    "#                 load_size: 256                           \n",
    "#          max_dataset_size: inf                           \n",
    "#                     model: cycle_gan                     \t[default: test]\n",
    "#                n_layers_D: 3                             \n",
    "#                      name: horse2zebra_cyclegan          \t[default: experiment_name]\n",
    "#                       ndf: 64                            \n",
    "#                      netD: basic                         \n",
    "#                      netG: resnet_9blocks                \n",
    "#                       ngf: 64                            \n",
    "#                no_dropout: True                          \n",
    "#                   no_flip: False                         \n",
    "#                      norm: instance                      \n",
    "#                  num_test: 50                            \n",
    "#               num_threads: 4                             \n",
    "#                 output_nc: 3                             \n",
    "#                     phase: test                          \n",
    "#                preprocess: resize_and_crop               \n",
    "#               results_dir: ./results/                    \n",
    "#            serial_batches: False                         \n",
    "#                    suffix:                               \n",
    "#                   verbose: False                         \n",
    "# ----------------- End -------------------\n",
    "# dataset [UnalignedDataset] was created\n",
    "# initialize network with normal\n",
    "# initialize network with normal\n",
    "# model [CycleGANModel] was created\n",
    "# loading the model from ./checkpoints/horse2zebra_cyclegan/latest_net_G_A.pth\n",
    "# loading the model from ./checkpoints/horse2zebra_cyclegan/latest_net_G_B.pth\n",
    "# ---------- Networks initialized -------------\n",
    "# [Network G_A] Total number of parameters : 11.378 M\n",
    "# [Network G_B] Total number of parameters : 11.378 M\n",
    "# -----------------------------------------------\n",
    "# creating web directory ./results/horse2zebra_cyclegan/test_latest\n",
    "# processing (0000)-th image... ['./datasets/horse2zebra/testA/n02381460_1000.jpg']\n",
    "# processing (0005)-th image... ['./datasets/horse2zebra/testA/n02381460_1110.jpg']\n",
    "# processing (0010)-th image... ['./datasets/horse2zebra/testA/n02381460_1260.jpg']\n",
    "# processing (0015)-th image... ['./datasets/horse2zebra/testA/n02381460_1420.jpg']\n",
    "# processing (0020)-th image... ['./datasets/horse2zebra/testA/n02381460_1690.jpg']\n",
    "# processing (0025)-th image... ['./datasets/horse2zebra/testA/n02381460_1830.jpg']\n",
    "# processing (0030)-th image... ['./datasets/horse2zebra/testA/n02381460_2050.jpg']\n",
    "# processing (0035)-th image... ['./datasets/horse2zebra/testA/n02381460_2460.jpg']\n",
    "# processing (0040)-th image... ['./datasets/horse2zebra/testA/n02381460_2870.jpg']\n",
    "# processing (0045)-th image... ['./datasets/horse2zebra/testA/n02381460_3040.jpg']\n"
   ]
  },
  {
   "source": [
    "### Real A\n",
    "![alt text](./screenshot/n02381460_1160_real_A.png)\n",
    "### G_A(Real_A)\n",
    "![alt text](./screenshot/n02381460_1160_fake_B.png)\n",
    "### G_B(G_A(Real_A))\n",
    "![alt text](./screenshot/n02381460_1160_rec_A.png)\n",
    "\n",
    "\n",
    "\n",
    "### Real B\n",
    "![alt text](./screenshot/n02381460_1160_real_B.png)\n",
    "### G_B(Real_B)\n",
    "![alt text](./screenshot/n02381460_1160_fake_A.png)\n",
    "### G_A(G_B(Real_B))\n",
    "![alt text](./screenshot/n02381460_1160_rec_B.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. AITICT 2 Celeb\n",
    "\n",
    "The last updated dataset are given in the piazza\n",
    "\n",
    "https://www.cs.ait.ac.th/~mdailey/celebA-317.zip\n",
    "\n",
    "https://www.cs.ait.ac.th/~mdailey/ait-ict.zip\n",
    "\n",
    "I created a folder int2celeb inside the datasets folder. The extracted ait-ict.zip is named trainA and trainB for the celebA-317.zip case.\n",
    "In a nutshell, here is how the folder is constructed.\n",
    "\n",
    "- datasets\n",
    "  - ict2caleb\n",
    "    - trainA (ait-ict)\n",
    "    - trainB (celebA-317)\n",
    "\n",
    "The training commands are as follow.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unset http_proxy\n",
    "# unset https_proxy\n",
    "# nohup python3 -u train.py --dataroot ./datasets/ict2celeb --gpu_ids 1 --name ict2celeb --model cycle_gan > nohup_ict2celeb.out"
   ]
  },
  {
   "source": [
    "The last 4 epochs loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate 0.0000079 -> 0.0000059\n",
    "# (epoch: 197, iters: 68, time: 0.270, data: 0.001) D_A: 0.036 G_A: 0.923 cycle_A: 0.523 idt_A: 0.279 D_B: 0.060 G_B: 0.780 cycle_B: 0.808 idt_B: 0.227 \n",
    "# (epoch: 197, iters: 168, time: 0.267, data: 0.001) D_A: 0.057 G_A: 0.855 cycle_A: 0.485 idt_A: 0.159 D_B: 0.126 G_B: 0.825 cycle_B: 0.494 idt_B: 0.183 \n",
    "# (epoch: 197, iters: 268, time: 1.540, data: 0.001) D_A: 0.117 G_A: 0.734 cycle_A: 0.527 idt_A: 0.139 D_B: 0.076 G_B: 0.598 cycle_B: 0.395 idt_B: 0.172 \n",
    "# End of epoch 197 / 200 \t Time Taken: 86 sec\n",
    "# learning rate 0.0000059 -> 0.0000040\n",
    "# (epoch: 198, iters: 51, time: 0.270, data: 0.001) D_A: 0.088 G_A: 0.745 cycle_A: 0.542 idt_A: 0.177 D_B: 0.052 G_B: 0.822 cycle_B: 0.517 idt_B: 0.158 \n",
    "# (epoch: 198, iters: 151, time: 0.271, data: 0.001) D_A: 0.056 G_A: 0.921 cycle_A: 0.460 idt_A: 0.198 D_B: 0.088 G_B: 0.620 cycle_B: 0.524 idt_B: 0.146 \n",
    "# (epoch: 198, iters: 251, time: 0.271, data: 0.001) D_A: 0.043 G_A: 0.769 cycle_A: 0.427 idt_A: 0.249 D_B: 0.174 G_B: 0.400 cycle_B: 0.736 idt_B: 0.147 \n",
    "# End of epoch 198 / 200 \t Time Taken: 85 sec\n",
    "# learning rate 0.0000040 -> 0.0000020\n",
    "# (epoch: 199, iters: 34, time: 1.505, data: 0.001) D_A: 0.034 G_A: 0.949 cycle_A: 0.471 idt_A: 0.201 D_B: 0.083 G_B: 0.779 cycle_B: 0.504 idt_B: 0.278 \n",
    "# (epoch: 199, iters: 134, time: 0.269, data: 0.001) D_A: 0.127 G_A: 0.469 cycle_A: 0.408 idt_A: 0.206 D_B: 0.086 G_B: 0.647 cycle_B: 0.564 idt_B: 0.165 \n",
    "# (epoch: 199, iters: 234, time: 0.269, data: 0.001) D_A: 0.159 G_A: 0.871 cycle_A: 0.421 idt_A: 0.206 D_B: 0.091 G_B: 0.672 cycle_B: 0.500 idt_B: 0.156 \n",
    "# End of epoch 199 / 200 \t Time Taken: 86 sec\n",
    "# learning rate 0.0000020 -> 0.0000000\n",
    "# (epoch: 200, iters: 17, time: 0.270, data: 0.001) D_A: 0.057 G_A: 0.704 cycle_A: 0.413 idt_A: 0.252 D_B: 0.049 G_B: 0.426 cycle_B: 0.597 idt_B: 0.277 \n",
    "# (epoch: 200, iters: 117, time: 1.578, data: 0.001) D_A: 0.074 G_A: 0.770 cycle_A: 0.397 idt_A: 0.198 D_B: 0.062 G_B: 0.687 cycle_B: 0.584 idt_B: 0.147 \n",
    "# (epoch: 200, iters: 217, time: 0.268, data: 0.001) D_A: 0.056 G_A: 0.837 cycle_A: 0.428 idt_A: 0.158 D_B: 0.090 G_B: 0.629 cycle_B: 0.467 idt_B: 0.127 \n",
    "# (epoch: 200, iters: 317, time: 0.268, data: 0.001) D_A: 0.045 G_A: 0.867 cycle_A: 0.472 idt_A: 0.259 D_B: 0.119 G_B: 0.787 cycle_B: 0.806 idt_B: 0.174 \n",
    "# saving the model at the end of epoch 200, iters 63400\n",
    "# End of epoch 200 / 200 \t Time Taken: 89 sec"
   ]
  },
  {
   "source": [
    "## Result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ python3 test.py --dataroot ./datasets/ict2celeb --gpu_ids 1 --name ict2celeb --model cycle_gan\n",
    "# ----------------- Options ---------------\n",
    "#              aspect_ratio: 1.0                           \n",
    "#                batch_size: 1                             \n",
    "#           checkpoints_dir: ./checkpoints                 \n",
    "#                 crop_size: 256                           \n",
    "#                  dataroot: ./datasets/ict2celeb          \t[default: None]\n",
    "#              dataset_mode: unaligned                     \n",
    "#                 direction: AtoB                          \n",
    "#           display_winsize: 256                           \n",
    "#                     epoch: latest                        \n",
    "#                      eval: False                         \n",
    "#                   gpu_ids: 1                             \t[default: 0]\n",
    "#                 init_gain: 0.02                          \n",
    "#                 init_type: normal                        \n",
    "#                  input_nc: 3                             \n",
    "#                   isTrain: False                         \t[default: None]\n",
    "#                 load_iter: 0                             \t[default: 0]\n",
    "#                 load_size: 256                           \n",
    "#          max_dataset_size: inf                           \n",
    "#                     model: cycle_gan                     \t[default: test]\n",
    "#                n_layers_D: 3                             \n",
    "#                      name: ict2celeb                     \t[default: experiment_name]\n",
    "#                       ndf: 64                            \n",
    "#                      netD: basic                         \n",
    "#                      netG: resnet_9blocks                \n",
    "#                       ngf: 64                            \n",
    "#                no_dropout: True                          \n",
    "#                   no_flip: False                         \n",
    "#                      norm: instance                      \n",
    "#                  num_test: 50                            \n",
    "#               num_threads: 4                             \n",
    "#                 output_nc: 3                             \n",
    "#                     phase: test                          \n",
    "#                preprocess: resize_and_crop               \n",
    "#               results_dir: ./results/                    \n",
    "#            serial_batches: False                         \n",
    "#                    suffix:                               \n",
    "#                   verbose: False                         \n",
    "# ----------------- End -------------------\n",
    "# dataset [UnalignedDataset] was created\n",
    "# initialize network with normal\n",
    "# initialize network with normal\n",
    "# model [CycleGANModel] was created\n",
    "# loading the model from ./checkpoints/ict2celeb/latest_net_G_A.pth\n",
    "# loading the model from ./checkpoints/ict2celeb/latest_net_G_B.pth\n",
    "# ---------- Networks initialized -------------\n",
    "# [Network G_A] Total number of parameters : 11.378 M\n",
    "# [Network G_B] Total number of parameters : 11.378 M\n",
    "# -----------------------------------------------\n",
    "# creating web directory ./results/ict2celeb/test_latest\n",
    "# processing (0000)-th image... ['./datasets/ict2celeb/testA/000003.jpg']\n"
   ]
  },
  {
   "source": [
    "### Real A\n",
    "![alt text](./screenshot/000030_real_A.png)\n",
    "### G_A(Real_A)\n",
    "![alt text](./screenshot/000030_fake_B.png)\n",
    "### G_B(G_A(Real_A))\n",
    "![alt text](./screenshot/000030_rec_A.png)\n",
    "\n",
    "\n",
    "\n",
    "### Real B\n",
    "![alt text](./screenshot/000030_real_B.png)\n",
    "### G_B(Real_B)\n",
    "![alt text](./screenshot/000030_fake_A.png)\n",
    "### G_A(G_B(Real_B))\n",
    "![alt text](./screenshot/000030_rec_B.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}