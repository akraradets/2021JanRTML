----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 256                           
                 dataroot: ./datasets/horse2zebra        	[default: None]
             dataset_mode: unaligned                     
                direction: AtoB                          
              display_env: main                          
             display_freq: 400                           
               display_id: 1                             
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                 lambda_A: 10.0                          
                 lambda_B: 10.0                          
          lambda_identity: 0.5                           
                load_iter: 0                             	[default: 0]
                load_size: 286                           
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: cycle_gan                     
                 n_epochs: 100                           
           n_epochs_decay: 100                           
               n_layers_D: 3                             
                     name: horse2zebra_cyclegan          	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: resnet_9blocks                
                      ngf: 64                            
               no_dropout: True                          
                  no_flip: False                         
                  no_html: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 100                           
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                  verbose: False                         
----------------- End -------------------
dataset [UnalignedDataset] was created
The number of training images = 1334
initialize network with normal
initialize network with normal
initialize network with normal
initialize network with normal
model [CycleGANModel] was created
---------- Networks initialized -------------
[Network G_A] Total number of parameters : 11.378 M
[Network G_B] Total number of parameters : 11.378 M
[Network D_A] Total number of parameters : 2.765 M
[Network D_B] Total number of parameters : 2.765 M
-----------------------------------------------
/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.3) or chardet (3.0.4) doesn't match a supported version!
  RequestsDependencyWarning)
Setting up a new session...
create web directory ./checkpoints/horse2zebra_cyclegan/web...
/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
learning rate 0.0002000 -> 0.0002000
(epoch: 1, iters: 100, time: 0.269, data: 0.223) D_A: 0.516 G_A: 0.465 cycle_A: 2.570 idt_A: 0.816 D_B: 0.425 G_B: 0.571 cycle_B: 1.955 idt_B: 1.180 
(epoch: 1, iters: 200, time: 0.271, data: 0.001) D_A: 0.287 G_A: 0.218 cycle_A: 2.726 idt_A: 0.850 D_B: 0.280 G_B: 0.276 cycle_B: 1.849 idt_B: 1.343 
(epoch: 1, iters: 300, time: 0.274, data: 0.001) D_A: 0.328 G_A: 0.445 cycle_A: 2.792 idt_A: 0.851 D_B: 0.273 G_B: 0.371 cycle_B: 1.994 idt_B: 1.234 
(epoch: 1, iters: 400, time: 0.657, data: 0.001) D_A: 0.316 G_A: 0.272 cycle_A: 1.644 idt_A: 1.501 D_B: 0.377 G_B: 0.078 cycle_B: 2.981 idt_B: 0.787 
(epoch: 1, iters: 500, time: 0.278, data: 0.001) D_A: 0.334 G_A: 0.147 cycle_A: 1.808 idt_A: 0.972 D_B: 0.379 G_B: 0.686 cycle_B: 2.022 idt_B: 0.776 
(epoch: 1, iters: 600, time: 0.278, data: 0.001) D_A: 0.325 G_A: 0.454 cycle_A: 2.329 idt_A: 1.201 D_B: 0.315 G_B: 0.297 cycle_B: 2.550 idt_B: 1.160 
(epoch: 1, iters: 700, time: 0.286, data: 0.001) D_A: 0.174 G_A: 0.388 cycle_A: 2.788 idt_A: 1.446 D_B: 0.179 G_B: 0.588 cycle_B: 3.010 idt_B: 1.005 
(epoch: 1, iters: 800, time: 0.417, data: 0.001) D_A: 0.180 G_A: 0.372 cycle_A: 2.465 idt_A: 0.916 D_B: 0.316 G_B: 0.522 cycle_B: 1.902 idt_B: 0.830 
(epoch: 1, iters: 900, time: 0.287, data: 0.001) D_A: 0.211 G_A: 0.320 cycle_A: 4.017 idt_A: 0.885 D_B: 0.225 G_B: 0.551 cycle_B: 1.917 idt_B: 1.389 
(epoch: 1, iters: 1000, time: 0.286, data: 0.001) D_A: 0.251 G_A: 0.161 cycle_A: 2.847 idt_A: 1.350 D_B: 0.221 G_B: 0.436 cycle_B: 2.746 idt_B: 1.292 
(epoch: 1, iters: 1100, time: 0.296, data: 0.001) D_A: 0.204 G_A: 0.548 cycle_A: 2.252 idt_A: 1.531 D_B: 0.284 G_B: 0.355 cycle_B: 3.095 idt_B: 1.049 
(epoch: 1, iters: 1200, time: 0.423, data: 0.001) D_A: 0.284 G_A: 0.451 cycle_A: 2.065 idt_A: 0.945 D_B: 0.179 G_B: 0.347 cycle_B: 1.690 idt_B: 0.872 
(epoch: 1, iters: 1300, time: 0.290, data: 0.001) D_A: 0.346 G_A: 0.379 cycle_A: 1.353 idt_A: 1.002 D_B: 0.345 G_B: 0.358 cycle_B: 2.060 idt_B: 0.733 
End of epoch 1 / 200 	 Time Taken: 375 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 2, iters: 66, time: 0.296, data: 0.001) D_A: 0.230 G_A: 0.231 cycle_A: 2.202 idt_A: 0.978 D_B: 0.170 G_B: 0.316 cycle_B: 2.664 idt_B: 0.846 
(epoch: 2, iters: 166, time: 0.298, data: 0.001) D_A: 0.334 G_A: 0.386 cycle_A: 1.907 idt_A: 0.790 D_B: 0.312 G_B: 0.225 cycle_B: 1.581 idt_B: 0.957 
(epoch: 2, iters: 266, time: 0.707, data: 0.001) D_A: 0.226 G_A: 0.340 cycle_A: 1.687 idt_A: 1.338 D_B: 0.162 G_B: 0.419 cycle_B: 3.328 idt_B: 0.840 
(epoch: 2, iters: 366, time: 0.294, data: 0.001) D_A: 0.280 G_A: 0.730 cycle_A: 2.219 idt_A: 0.901 D_B: 0.291 G_B: 0.078 cycle_B: 1.875 idt_B: 0.910 
(epoch: 2, iters: 466, time: 0.289, data: 0.001) D_A: 0.327 G_A: 0.238 cycle_A: 2.464 idt_A: 0.629 D_B: 0.163 G_B: 0.409 cycle_B: 1.366 idt_B: 1.054 
(epoch: 2, iters: 566, time: 0.295, data: 0.001) D_A: 0.194 G_A: 0.789 cycle_A: 1.541 idt_A: 0.852 D_B: 0.142 G_B: 0.487 cycle_B: 1.755 idt_B: 0.563 
(epoch: 2, iters: 666, time: 0.595, data: 0.001) D_A: 0.136 G_A: 0.503 cycle_A: 1.471 idt_A: 1.187 D_B: 0.275 G_B: 0.234 cycle_B: 2.691 idt_B: 0.731 
(epoch: 2, iters: 766, time: 0.300, data: 0.001) D_A: 0.135 G_A: 0.866 cycle_A: 2.005 idt_A: 0.984 D_B: 0.213 G_B: 0.604 cycle_B: 2.421 idt_B: 1.049 
(epoch: 2, iters: 866, time: 0.304, data: 0.001) D_A: 0.312 G_A: 0.393 cycle_A: 2.108 idt_A: 0.876 D_B: 0.302 G_B: 0.455 cycle_B: 1.882 idt_B: 1.259 
(epoch: 2, iters: 966, time: 0.297, data: 0.001) D_A: 0.117 G_A: 0.340 cycle_A: 1.625 idt_A: 0.629 D_B: 0.276 G_B: 0.640 cycle_B: 1.417 idt_B: 0.742 
(epoch: 2, iters: 1066, time: 0.437, data: 0.001) D_A: 0.323 G_A: 0.537 cycle_A: 1.860 idt_A: 0.749 D_B: 0.165 G_B: 0.345 cycle_B: 1.905 idt_B: 0.991 
(epoch: 2, iters: 1166, time: 0.296, data: 0.001) D_A: 0.115 G_A: 0.462 cycle_A: 4.709 idt_A: 0.771 D_B: 0.097 G_B: 0.369 cycle_B: 1.685 idt_B: 2.334 
(epoch: 2, iters: 1266, time: 0.292, data: 0.001) D_A: 0.264 G_A: 0.291 cycle_A: 1.256 idt_A: 1.019 D_B: 0.084 G_B: 0.469 cycle_B: 1.976 idt_B: 0.656 
End of epoch 2 / 200 	 Time Taken: 393 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 3, iters: 32, time: 0.281, data: 0.001) D_A: 0.156 G_A: 0.756 cycle_A: 1.756 idt_A: 0.796 D_B: 0.117 G_B: 0.586 cycle_B: 1.821 idt_B: 0.819 
(epoch: 3, iters: 132, time: 0.749, data: 0.001) D_A: 0.148 G_A: 0.287 cycle_A: 1.417 idt_A: 0.640 D_B: 0.174 G_B: 0.223 cycle_B: 1.345 idt_B: 0.717 
(epoch: 3, iters: 232, time: 0.305, data: 0.001) D_A: 0.184 G_A: 0.344 cycle_A: 2.013 idt_A: 0.614 D_B: 0.410 G_B: 0.992 cycle_B: 1.398 idt_B: 0.891 
(epoch: 3, iters: 332, time: 0.299, data: 0.001) D_A: 0.420 G_A: 0.062 cycle_A: 1.309 idt_A: 0.802 D_B: 0.277 G_B: 0.609 cycle_B: 2.391 idt_B: 0.674 
(epoch: 3, iters: 432, time: 0.294, data: 0.001) D_A: 0.355 G_A: 0.210 cycle_A: 1.106 idt_A: 0.798 D_B: 0.279 G_B: 0.108 cycle_B: 1.696 idt_B: 0.559 
(epoch: 3, iters: 532, time: 0.423, data: 0.001) D_A: 0.198 G_A: 0.678 cycle_A: 1.855 idt_A: 0.725 D_B: 0.212 G_B: 0.565 cycle_B: 2.072 idt_B: 0.792 
(epoch: 3, iters: 632, time: 0.304, data: 0.001) D_A: 0.224 G_A: 0.304 cycle_A: 1.630 idt_A: 0.783 D_B: 0.284 G_B: 0.550 cycle_B: 1.781 idt_B: 0.751 
(epoch: 3, iters: 732, time: 0.291, data: 0.001) D_A: 0.094 G_A: 0.231 cycle_A: 1.271 idt_A: 0.629 D_B: 0.287 G_B: 0.465 cycle_B: 1.540 idt_B: 0.520 
(epoch: 3, iters: 832, time: 0.300, data: 0.001) D_A: 0.602 G_A: 0.045 cycle_A: 1.887 idt_A: 0.827 D_B: 0.482 G_B: 0.766 cycle_B: 1.749 idt_B: 0.795 
(epoch: 3, iters: 932, time: 0.430, data: 0.001) D_A: 0.111 G_A: 0.120 cycle_A: 2.116 idt_A: 1.271 D_B: 0.256 G_B: 0.664 cycle_B: 2.591 idt_B: 0.877 
(epoch: 3, iters: 1032, time: 0.295, data: 0.001) D_A: 0.356 G_A: 0.213 cycle_A: 1.271 idt_A: 0.651 D_B: 0.294 G_B: 0.275 cycle_B: 1.461 idt_B: 0.587 
(epoch: 3, iters: 1132, time: 0.295, data: 0.001) D_A: 0.373 G_A: 0.054 cycle_A: 1.383 idt_A: 0.765 D_B: 0.237 G_B: 0.207 cycle_B: 1.288 idt_B: 0.622 
(epoch: 3, iters: 1232, time: 0.290, data: 0.001) D_A: 0.118 G_A: 0.346 cycle_A: 1.646 idt_A: 0.636 D_B: 0.318 G_B: 0.110 cycle_B: 1.666 idt_B: 0.779 
(epoch: 3, iters: 1332, time: 0.562, data: 0.001) D_A: 0.163 G_A: 0.250 cycle_A: 2.410 idt_A: 1.106 D_B: 0.341 G_B: 1.117 cycle_B: 2.446 idt_B: 1.085 
End of epoch 3 / 200 	 Time Taken: 394 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 4, iters: 98, time: 0.302, data: 0.001) D_A: 0.249 G_A: 0.453 cycle_A: 1.193 idt_A: 0.847 D_B: 0.320 G_B: 0.937 cycle_B: 1.600 idt_B: 0.587 
(epoch: 4, iters: 198, time: 0.295, data: 0.001) D_A: 0.142 G_A: 0.512 cycle_A: 1.530 idt_A: 0.774 D_B: 0.225 G_B: 0.177 cycle_B: 2.259 idt_B: 0.553 
(epoch: 4, iters: 298, time: 0.297, data: 0.001) D_A: 0.117 G_A: 0.163 cycle_A: 3.400 idt_A: 0.987 D_B: 0.629 G_B: 0.057 cycle_B: 1.882 idt_B: 1.364 
(epoch: 4, iters: 398, time: 0.592, data: 0.001) D_A: 0.116 G_A: 0.528 cycle_A: 1.338 idt_A: 0.655 D_B: 0.202 G_B: 0.547 cycle_B: 1.648 idt_B: 0.594 
(epoch: 4, iters: 498, time: 0.299, data: 0.001) D_A: 0.101 G_A: 0.217 cycle_A: 1.626 idt_A: 0.658 D_B: 0.179 G_B: 0.446 cycle_B: 1.129 idt_B: 0.881 
