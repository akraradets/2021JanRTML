{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "1. Get a set of ImageNet pretrained weights for CSPDarknet53 from the Darknet GitHub repository"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/csdarknet53-omega_final.weights"
   ]
  },
  {
   "source": [
    "2. Add a method to load the pretrained weights into the backbone portion of your PyTorch YOLOv4 model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-02-12 03:11:10--  https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 12231 (12K) [text/plain]\n",
      "Saving to: ‘yolov4.cfg’\n",
      "\n",
      "yolov4.cfg          100%[===================>]  11.94K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2021-02-12 03:11:11 (420 KB/s) - ‘yolov4.cfg’ saved [12231/12231]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/csdarknet53-omega.cfg\n",
    "# !mkdir cfg\n",
    "# !mv csdarknet53-omega.cfg cfg/\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
    "# !mv yolov4.cfg cfg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blocks = darknet.parse_cfg(\"cfg/csdarknet53-omega.cfg\")\n",
    "print(darknet.create_modules(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish', 'backbone': '0'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-2']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-1', '-7']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-2']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-1', '-10']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-2']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-1', '-28']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-2']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-1', '-28']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-2']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish'}\n{'type': 'route', 'layers': ['-1', '-16']}\n{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'mish', 'backbone': '1'}\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "from myDarknet import MyDarknet\n",
    "import darknet\n",
    "model = MyDarknet(\"cfg/yolov4.cfg\")\n",
    "model.load_weights(\"csdarknet53-omega_final.weights\", backbone=True)"
   ]
  },
  {
   "source": [
    "3. Implement a basic train_yolo function similar to the train_model function you developed in previous labs for classifiers that preprocesses the input with basic augmentation transformations, converts the anchor-relative outputs to bounding box coordinates, computes MSE loss for the bounding box coordinates, backpropagates the loss, and takes a step for the optimizer. Use the recommended IoU thresholds to determine which predicted bounding boxes to include in the loss. You will find many examples of how to do this online"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}