{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "rtml",
   "display_name": "rtml",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 1.6786,  0.6260, -0.4821])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# State transition function\n",
    "\n",
    "T = torch.tensor([[[0.8, 0.1, 0.1],\n",
    "                   [0.1, 0.6, 0.3]],\n",
    "                  [[0.7, 0.2, 0.1],\n",
    "                   [0.1, 0.8, 0.1]],\n",
    "                  [[0.6, 0.2, 0.2],\n",
    "                   [0.1, 0.4, 0.5]]])\n",
    "\n",
    "# Reward function\n",
    "\n",
    "R = torch.tensor([1.,0.,-1.])\n",
    "\n",
    "# Discount factor\n",
    "\n",
    "gamma = 0.5\n",
    "\n",
    "\n",
    "def policy_evaluation(policy, trans_matrix, rewards, gamma, threshold):\n",
    "    n_state = policy.shape[0]\n",
    "    V = torch.zeros(n_state)\n",
    "    while True:\n",
    "        V_temp = torch.zeros(n_state)\n",
    "        for state, actions in enumerate(policy):\n",
    "            for action, action_prob in enumerate(actions):\n",
    "                V_temp[state] += action_prob * (rewards[state] + gamma * torch.dot(trans_matrix[state, action], V))\n",
    "        max_delta = torch.max(torch.abs(V-V_temp))\n",
    "        V = V_temp.clone()\n",
    "        if max_delta <= threshold:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "threshold = 0.0001\n",
    "policy_optimal = torch.tensor([[1.0, 0.0],\n",
    "                               [1.0, 0.0],\n",
    "                               [1.0, 0.0]])\n",
    "V = policy_evaluation(policy_optimal, T, R, gamma, threshold)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(policy, trans_matrix, rewards, gamma, threshold):\n",
    "    n_state = policy.shape[0]\n",
    "    V = torch.zeros(n_state)\n",
    "    while True:\n",
    "        V_temp = torch.zeros(n_state)\n",
    "        for state in range(n_state):\n",
    "            action = int(policy[state].item())\n",
    "            for new_state in range(n_state):\n",
    "                trans_prop = trans_matrix[state, action, new_state]\n",
    "                reward = rewards[state, action, new_state]\n",
    "                V_temp[state] += trans_prop * (reward + gamma * V[new_state])\n",
    "        max_delta = torch.max(torch.abs(V-V_temp))\n",
    "        V = V_temp.clone()\n",
    "        if max_delta <= threshold:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_improvement(trans_matrix, rewards, gamma):\n",
    "    n_state = trans_matrix.shape[0]\n",
    "    n_action = trans_matrix.shape[1]\n",
    "    policy = torch.zeros(n_state)\n",
    "\n",
    "    for state in range(n_state):\n",
    "        v_actions = torch.zeros(n_action)\n",
    "        for action in range(n_action):\n",
    "            for new_state in range(n_state):\n",
    "                trans_prop = trans_matrix[state, action, new_state]\n",
    "                reward = rewards[state, action, new_state]\n",
    "                v_actions[action] += trans_prop * (reward + gamma * V[new_state])\n",
    "        policy[state] = torch.argmax(v_actions)\n",
    "    return policy\n",
    "\n",
    "def policy_iteration(trans_matrix, rewards, gamma, threshold):\n",
    "    n_state = trans_matrix.shape[0]\n",
    "    n_action = trans_matrix.shape[1]\n",
    "    policy = torch.randint(high=n_action, size=(n_state,)).float()\n",
    "    while True:\n",
    "        V = policy_evaluation(policy, trans_matrix, rewards, gamma, threshold)\n",
    "        policy_improved = policy_improvement(trans_matrix, rewards, gamma)\n",
    "        if torch.equal(policy_improved, policy):\n",
    "            return V, policy_improved\n",
    "        policy = policy_improved\n",
    "\n",
    "# Reward R(s,a,s') example\n",
    "\n",
    "R2 = torch.tensor([[[0.1,0.,-0.2],\n",
    "                   [0.2,0.,-0.1]],\n",
    "                  [[0.3,0.,-0.5],\n",
    "                   [0.1,0.,-0.2]],\n",
    "                  [[0.2,0.,-0.1],\n",
    "                   [1.,0.,-1.]]])\n",
    "\n",
    "V_optimal, optimal_policy = policy_iteration(T, R2, gamma, threshold)\n",
    "print(V_optimal)\n",
    "print(optimal_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.1352, 0.2405, 0.1829])\n"
     ]
    }
   ],
   "source": [
    "def value_iteration(trans_matrix, rewards, gamma, threshold):\n",
    "    n_state = trans_matrix.shape[0]\n",
    "    n_action = trans_matrix.shape[1]\n",
    "    V = torch.zeros(n_state)\n",
    "    while True:\n",
    "        V_temp = torch.zeros(n_state)\n",
    "        for state in range(n_state):\n",
    "            v_actions = torch.zeros(n_action)\n",
    "            for action in range(n_action):\n",
    "                for new_state in range(n_state):\n",
    "                    trans_prop = trans_matrix[state, action, new_state]\n",
    "                    reward = rewards[state, action, new_state]\n",
    "                    v_actions[action] += trans_prop * (reward + gamma * V[new_state])\n",
    "            V_temp[state] = torch.max(v_actions)\n",
    "        max_delta = torch.max(torch.abs(V-V_temp))\n",
    "        V = V_temp.clone()\n",
    "        if max_delta <= threshold:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "R2 = torch.tensor([[[0.1, 0., -0.2],\n",
    "                    [0.2, 0., -0.1]],\n",
    "                   [[0.3, 0., -0.5],\n",
    "                    [0.1, 0., -0.2]],\n",
    "                   [[0.2, 0., -0.1],\n",
    "                    [1. , 0., -1. ]]])\n",
    "\n",
    "V = value_iteration(T, R2, gamma, threshold)\n",
    "print(V)"
   ]
  }
 ]
}