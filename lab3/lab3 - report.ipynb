{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# RTML lab3 report - st121413\n",
    "\n",
    "1. Get your Docker container running on the GPU server and get VSCode talking to your Docker container as in previous labs.\n",
    "\n",
    "2. Set up the ResNet and ResSENet classes with supporting functions using a good structure (one class per file) as in Lab 02. Fix any warnings pylint finds in our sample code. :-)\n",
    "\n",
    "3. Switch to 256x256 scaling and 224x224 cropping for CIFAR as standardized for ImageNet. Modify the implementation to use the same convolutions (e.g., initial 7x7) and other layer settings found in the ResNet paper. Find competitive hyperparameters for ResNet18 and ResSENet18 you can and report your results.\n",
    "\n",
    "4. As practice in transfer learning for very small datasets, take your best ResSENet18 from the exercise above and fine tune it on the Chihuahua vs. Muffins Challenge. You only have 16 examples from each category, so to get a reasonable validation accuracy estimate, use 8-fold cross validation for this experiment. In particular, fine tune your model 8 different times, holding out two examples from each category as the validation set each time, report the average accuracy as the expected accuracy of your model, then train a final fine-tuned model on all of the data with the hyperparameters found during cross validation. Lastly, test the final model on a few muffin and chihuahua images you find online that are not identical to the examples in the meme. Have fun with it!\n",
    "\n",
    "# Lab report\n",
    "As usual, write up an introduction, methods, results, and conclusion based on your work as a Jupyter notebook, export to PDF, and submit in the Google Classroom before next week's lab.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "from myNetwork.mySENet import SENet\n",
    "\n",
    "SENet.a('b')\n"
   ]
  }
 ]
}