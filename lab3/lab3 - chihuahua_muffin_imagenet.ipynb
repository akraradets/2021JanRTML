{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1801.09573.pdf\n",
    "# Datasets\n",
    "# We have collected the 1000 images from the internet in 2 categories as muffin and Chihuahua\n",
    "# including 200 images from Oxford pet animal dataset [7] as shown in Figure 3. Please note here, all\n",
    "# resources as images from the internet is for research purpose only, we donâ€™t own any of them. ImageNet\n",
    "# [5] also includes 1750 Chihuahua and 1335 various type of muffin images already.\n",
    "\n",
    "# http://image-net.org/synset?wnid=n02085620 : 1750 Chihuahua\n",
    "# http://image-net.org/synset?wnid=n07690273 : 1335 muffins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://aviaryan.com/blog/gsoc/downloading-files-from-urls\n",
    "# import requests\n",
    "# def is_downloadable(url):\n",
    "#     \"\"\"\n",
    "#     Does the url contain a downloadable resource\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         h = requests.head(url, allow_redirects=True)\n",
    "#     except:\n",
    "#         return False\n",
    "#     header = h.headers\n",
    "#     content_type = header.get('content-type')\n",
    "#     if content_type == None:\n",
    "#         return False\n",
    "#     if 'text' in content_type.lower():\n",
    "#         return False\n",
    "#     if 'html' in content_type.lower():\n",
    "#         return False\n",
    "#     return True\n",
    "\n",
    "# file1 = open('chihuahua.txt', 'r')\n",
    "# Lines = file1.readlines()\n",
    "# count = 0\n",
    "# for line in Lines:\n",
    "#     print(line)\n",
    "#     if(is_downloadable(line)):\n",
    "#         count += 1\n",
    "#         r = requests.get(line, allow_redirects=True)\n",
    "#         open(f'data/chihuahua/{count}.jpg', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file1 = open('muffin.txt', 'r')\n",
    "# Lines = file1.readlines()\n",
    "# count = 0\n",
    "# for line in Lines:\n",
    "#     print(line)\n",
    "#     if(is_downloadable(line)):\n",
    "#         count += 1\n",
    "#         r = requests.get(line, allow_redirects=True)\n",
    "#         open(f'data/muffin/{count}.jpg', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset ImageFolder\n    Number of datapoints: 1988\n    Root location: data/train\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "from copy import copy\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Allow augmentation transform for training set, no augementation for val/test set\n",
    "# Normalize(mean, std, inplace=False)\n",
    "# mean, std = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "mean, std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "preprocess_augment = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])\n",
    "\n",
    "\n",
    "full_train_dataset = torchvision.datasets.ImageFolder('data/imagenet')\n",
    "print(full_train_dataset)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_train_dataset, [1600, 1988-1600])\n",
    "train_dataset.dataset = copy(full_train_dataset)\n",
    "train_dataset.dataset.transform = preprocess_augment\n",
    "val_dataset.dataset.transform = preprocess\n",
    "\n",
    "# DataLoaders for the three datasets\n",
    "BATCH_SIZE=4\n",
    "NUM_WORKERS=2\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True , num_workers=NUM_WORKERS)\n",
    "val_dataloader   = torch.utils.data.DataLoader(val_dataset  , batch_size=BATCH_SIZE,shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# # get some random training images\n",
    "# dataiter = iter(train_dataloader)\n",
    "# images, labels = dataiter.next()\n",
    "# print(labels)\n",
    "# toshow = torchvision.utils.make_grid(images)\n",
    "# toshow = toshow / 2 + 0.5     # unnormalize\n",
    "# npimg = toshow.numpy()\n",
    "# plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "# plt.show()\n",
    "classes = np.array(['chihuahua','muffin'])\n",
    "# print(labels, classes[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "\n",
    "from myNetwork.myResNet import ResNet\n",
    "from trainer import trainer\n",
    "\n",
    "def SEResNet18(num_classes = 10):\n",
    "    return ResNet(ResNet._BLOCK_SEBASIC, [2, 2, 2, 2], num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = SEResNet18()\n",
    "model.load_state_dict(torch.load('result-20210129-104338/seresnet18_adam_0.01.pth'))\n",
    "model.classifier[2] = nn.Linear(512,2)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params_to_update = model.parameters()\n",
    "# Now we'll use Adam optimization\n",
    "optimizer = optim.Adam(params_to_update, lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=5)\n",
    "t = trainer(device,criterion, optimizer,scheduler)\n",
    "model = t.train(model, dataloaders, num_epochs=60, weights_name='seresnet18_chihuahua_muffin_adam_0.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset ImageFolder\n    Number of datapoints: 16\n    Root location: data/test\n    StandardTransform\nTransform: Compose(\n               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n               CenterCrop(size=(224, 224))\n               ToTensor()\n               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n           )\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder('data/test', transform=preprocess)\n",
    "print(test_dataset)\n",
    "test_dataloader   = torch.utils.data.DataLoader(test_dataset  , batch_size=BATCH_SIZE,shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:1\n",
      "===== Testing =====\n",
      "Accuracy of the network on the 16 test images: 87 %\n",
      "Accuracy of chihuahua : 100 %\n",
      "Accuracy of muffin : 75 %\n"
     ]
    }
   ],
   "source": [
    "from myNetwork.myResNet import ResNet\n",
    "from trainer import trainer\n",
    "\n",
    "def SEResNet18(num_classes = 10):\n",
    "    return ResNet(ResNet._BLOCK_SEBASIC, [2, 2, 2, 2], num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = SEResNet18()\n",
    "model.classifier[2] = nn.Linear(512,2)\n",
    "model.load_state_dict(torch.load('result-20210130-150221/seresnet18_chihuahua_muffin_adam_0.01.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params_to_update = model.parameters()\n",
    "# Now we'll use Adam optimization\n",
    "optimizer = optim.Adam(params_to_update, lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=5)\n",
    "t = trainer(device,criterion, optimizer,scheduler)\n",
    "t.test(model,test_dataloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(classes))"
   ]
  }
 ]
}