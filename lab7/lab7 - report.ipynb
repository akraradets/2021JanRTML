{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab 7 - st121413\n",
    "\n",
    "\n",
    "1. Reproduce the vanilla GAN and DCGAN results on MNIST and CIFAR. Get the training and test loss for the generator and discriminator over time, plot them, and interpret them.\n",
    "\n",
    "2. Develop your own GAN to model data generated as follows:\n",
    "You should create a PyTorch DataSet that generates the 2D data in the __init__() method, outputs a sample in the __getitem__() method, and returns the dataset size in the __len__() method. Use the vanilla GAN approach above with an appropriate structure for the generator. Can your GAN generate a convincing facsimile of a set of samples from the actual distribution?\n",
    "\n",
    "\n",
    "3. Use the DCGAN (or an improvement to it) to build a generator for a face image set of your choice. Can you get realistic faces that are not in the training set?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Reproduce the VanillaGAN and DGAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The proof of reproducing the lab manual can be seen from the series of images from TensorboardX below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### VGAN - MNIST\n",
    "Loss:\n",
    "Discriminator Loss is growning while the Generator loss is decreasing.\n",
    "\n",
    "This could be that the objective of Discriminator is trying to classify a real data from fake one. Once the generator gets better at faking the data, a Discriminator could not classify the real fron the fake anymore.\n",
    "\n",
    "The fake data generated at iteration 27,800 is also shown below.\n",
    "\n",
    "![alt text](./screenshot/VGAN-lost.png)\n",
    "\n",
    "![alt text](./screenshot/VGAN-result.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### DCGAN - CIFAR10\n",
    "\n",
    "My DCGAN has totally different story from VanillaGAN.\n",
    "\n",
    "The losses of Discriminator is all over the place. There is one iteration that the loss is very high and after that is alternate between super high and super low (0.9 or 0.0001)\n",
    "\n",
    "The same case is applied to Generator Loss. It is reduced until that iteration and start to jump around.\n",
    "\n",
    "This could the unstable problem we talked about in WGAN.\n",
    "\n",
    "![alt text](./screenshot/DCGAN-loss.png)\n",
    "\n",
    "![alt text](./screenshot/DCGAN-result.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. VanillaGAN on SNAKE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, here is my snake dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class Snake(torch.utils.data.Dataset):\n",
    "    def __init__(self, size = 100000):\n",
    "        import numpy as np\n",
    "        theta = torch.rand(size) * 2 * np.pi\n",
    "        # torch.RAND\n",
    "        # torch.rand(*size, *, out=None, dtype=None, layout=np.strided, device=None, requires_grad=False) → Tensor\n",
    "        # Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)[0,1)\n",
    "        r = torch.randn(size)\n",
    "        # np.RANDN\n",
    "        # np.randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "        # Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution).\n",
    "        self.size = size\n",
    "        self.x = (10 + r) * torch.cos(theta)\n",
    "        mask = (theta >= (0.5 * np.pi)) & (theta <= (1.5 * np.pi))\n",
    "        offset = torch.where(mask, torch.tensor(10.0), torch.tensor(-10.0))\n",
    "        self.y = (10 + r) * torch.sin(theta) + offset\n",
    "\n",
    "        self.x = torch.reshape(self.x, (1,-1))\n",
    "        self.y = torch.reshape(self.y, (1,-1))\n",
    "        self.data = torch.cat([ self.x, self.y], 0 ).T\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "source": [
    "Second, about fixing VanillaGAN.\n",
    "\n",
    "At first, I change the number of <code>in feature</code> of Discriminator to 2 and Generator <code>out feature</code> to 2.\n",
    "\n",
    "I ran it for a while and observed that my Generator can only output a certain range of number. \n",
    "\n",
    "I analyzed the Generator and decided to remove the last <code>tanh</code>. This function clipped out the output and I don't want that.\n",
    "\n",
    "After doing so, the training goes well.\n",
    "\n",
    "This is the setup where the <code>z</code> (input noise) space is 100-dimension. \n",
    "\n",
    "Later on, I found out from Chichan that I suppose to use <code>z</code> space of 2-dimension. \n",
    "\n",
    "Therefore, I changed the noise function to generate noise of size 2 and generator to accept data of size 2.\n",
    "\n",
    "The loss graph can be found below.\n",
    "\n",
    "\n",
    "The green line: 100-dimension z\n",
    "\n",
    "The grey line: 2-dimension z\n",
    "\n",
    "![alt text](./screenshot/VGAN-loss-snake.png)\n",
    "\n",
    "The last 2 results of generator\n",
    "\n",
    "![alt text](./screenshot/VGAN-result-snake.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3. DCGAN on Face (CelebA)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "I choosed to use torchvision dataset named CelebA because it already there in the library.\n",
    "\n",
    "The downloading procedure has some issue but I managed to make it working.\n",
    "\n",
    "I modify not thing from DCGAN and just run the training because I want to get this result as a baseline.\n",
    "\n",
    "My docker decided to not cooperate and vanished multiple times.\n",
    "\n",
    "At the time of writing, my model is still training very slowly.\n",
    "\n",
    "I share you my current result.\n",
    "\n",
    "![alt text](./screenshot/DCGAN-loss-face.png)\n",
    "\n",
    "![alt text](./screenshot/DCGAN-result-face.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "From my analysis, I think the dataset is not only contain faces but rather an image of Celebrity with poses. The varity is just to big for this small Generator to learn.\n",
    "\n",
    "Since the Generator failed to output the image, the discriminator has en easy time seperate real data from fake data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### update 6/03/2021\n",
    "\n",
    "I have trained DCGAN on face again using ait-ict.zip given for the cycle gan the reason is\n",
    "\n",
    "1. The generator we have does not has a lot of weight to adjust.\n",
    "2. This ait-ict dataset has only 300 images with better face alignment.\n",
    "\n",
    "I strongly believe that this will allow my generator to learn.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Experiment 1 - DCGAN + ICT face\n",
    "\n",
    "I ran about 300 epochs and observed that the generator learned much better than the CelebA. However, the face does not clear. I guess it is due to 3 channels. Therefore, I decide to stop the train.\n",
    "\n",
    "![alt text](./screenshot/DCGAN-ICT-loss.png)\n",
    "\n",
    "![alt text](./screenshot/DCGAN-ICT-result.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Experiment 2 - DCGAN + ICT grey face\n",
    "\n",
    "I convert the images to 1 channel with resize to 64x64. Then I modify DCGAN to output an images of 1 channel (Generator) and classify on 1 channel image (Discriminator)\n",
    "\n",
    "As shown in the firgures below, my GAN doing great until at one epoch it turned into mode collapse and onward.\n",
    "\n",
    "![alt text](./screenshot/DCGAN-ICT-grey-loss.png)\n",
    "\n",
    "![alt text](./screenshot/DCGAN-ICT-grey-1.png)\n",
    "\n",
    "![alt text](./screenshot/DCGAN-ICT-grey-2.png)\n",
    "\n",
    "![alt text](./screenshot/DCGAN-ICT-grey-3.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}