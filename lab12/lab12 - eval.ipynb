{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# lab12 - st121413"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## In-lab exercises\n",
    "\n",
    "1. Spend some time to understand the Transformer and Speech Recognition examples.\n",
    " - I did this in the main_\\[modelname\\].py and save the best model in /checkpoint for the next one\n",
    " - https://github.com/akraradets/2021JanRTML/tree/main/lab12\n",
    "2. After training, test the two models on some data (text, audio) you provide yourself"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Transformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from myTransformer import *\n",
    "from utils import *\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = load_vocab('checkpoint/transformer_vocab.pickle')\n",
    "batch_size = 10\n",
    "def data_process(raw_text_iter, vocab, tokenizer):\n",
    "    data = [torch.tensor([vocab[token] for token in tokenizer(item)], dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target\n",
    "\n",
    "bptt = 35\n",
    "text = \"Visual Studio Code is a lightweight yet full featured cross platform IDE for software development that has recently caught up in terms of capabilities and popularity with other popular IDEs for Python such as PyCharm. It is reputed to be easier to configure and use, also. We'll give it a try this semester.\"\n",
    "text_tensor = data_process(text, vocab, tokenizer)\n",
    "text_batch = batchify(text_tensor, batch_size)"
   ]
  },
  {
   "source": [
    "ntokens = len(vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "model.load_state_dict(torch.load('checkpoint/transformer.pth'))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            if data.size(0) != bptt:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            output = eval_model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)\n",
    "\n",
    "test_loss = evaluate(model, text_batch)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(test_loss, math.exp(test_loss)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| End of training | test loss  8.54 | test ppl  5110.08\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## Speech Recognition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Homework\n",
    "\n",
    "Since you're all extremely busy with your projects (RIGHT??), for the homework for this week,\n",
    "write an explanation of the steps that would be needed to adapt the PyTorch transformer to\n",
    "the speech recognition task. Be specific in how you would do the implementation, but you do\n",
    "not need to ac"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}